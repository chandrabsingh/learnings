{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c1a2002",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    ">>> Work in Progress (Following are the lecture notes of Prof Percy Liang/Prof Dorsa Sadigh - CS221 - Stanford. This is my interpretation of his excellent teaching and I take full responsibility of any misinterpretation/misinformation provided herein.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51f58ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture 6: Search 2 - A* | Stanford CS221\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95730314",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uniform Cost Search - Last Lecture\n",
    "- util function - ProrityQueue  \n",
    "\n",
    "<img src=\"images/06_uniformCostAlgoUtil.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffaeff4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- algorithm implementation  \n",
    "\n",
    "<img src=\"images/06_uniformCostAlgo.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f280d1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- algorithm implementation  \n",
    "\n",
    "<img src=\"images/06_uniformCostAlgo.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e643249",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- what is the runtime of UCS\n",
    "  - $O(n\\log n)$\n",
    "    - log n is because of book-keeping of priorityQueue\n",
    "    - n is all the states we have explored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a17019f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why UCS returns the best minimum cost path\n",
    "### DP vs UCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317787f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Roadmap\n",
    "- Learning costs - 3rd Paradigm\n",
    "- A* search - ways of making search faster\n",
    "- Relaxation - type of strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e27e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Learning - Transporation Search\n",
    "- Transportation example\n",
    "  - Start state: 1\n",
    "  - Walk action: from s to s+1\n",
    "  - Tram action: from s to 2s\n",
    "  - End state: n\n",
    "- Solution\n",
    "  - we learnt earlier how to find the best path to get from state x to state y\n",
    "  - but we dont know if this is the most optimal cost \n",
    "  - we need to learn the costs to walk and in tram\n",
    "  - we know the path/trajectory based on data\n",
    "  - but we dont know the cost function that was being optimized to get to the best solution \n",
    "    - this is learning\n",
    "    - this cost function can then be applied say to robot\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1f0b93",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Learning as an inverse problem\n",
    "- Search is a forward problem\n",
    "  - given a cost(s,a), we find the sequence of actions\n",
    "- Learning is an inverse problem\n",
    "  - given the sequence of actions, find the cost(s,a)\n",
    "  \n",
    "- input x: search prob w/o costs\n",
    "- output y: solution path\n",
    "\n",
    "    - w - will be weights\n",
    "    - w[a1] = w[walk]\n",
    "    - w[a2] = w[tram]\n",
    "    - w's are the costs of going from 1 to 2\n",
    "    - say walking cost is 3, and tram cost is 2\n",
    "    - update these values, so that we get the optimal path of\n",
    "    - w[a1] = w[walk] = 3\n",
    "    - w[a2] = w[tram] = 2\n",
    "    - y(optimal solution) - walk, walk, walk - the cost is 3+3+3 = 9\n",
    "    - y'(prediction solution) - walk, tram - the cost is 3+2=5\n",
    "    - so i will pick prediction path\n",
    "    - first go over all the values of optimal values of y and lower value of w[walk] -> 3 -> 2 -> 1 -> 0\n",
    "    - then go over all the prediction values of y' and increase those value -> 0 -> 1\n",
    "    - Repeat doing this and see if it converges\n",
    "    \n",
    "<img src=\"images/06_learningProblem.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4451712b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/06_learningProblemOnBoard.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0001d2a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How to compute the cost?\n",
    "\n",
    "- cost of a path is the sum of all the paths\n",
    "- this is called __Structured Perceptron__\n",
    "\n",
    "<img src=\"images/06_learningProblemOnBoard2.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cefc2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Structured Perceptron\n",
    "- Algo in class\n",
    "\n",
    "<img src=\"images/06_structuredPerceptronAlgo.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f8e1a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Update w based on subtracting the features over true path plus the features over predicted path\n",
    "- This is Collins algorithm\n",
    "  - he used this in NLP - to match part of speech and tag to sentence moving the scores up or down\n",
    "  - Fruit flies like a banana -> Noun Noun Verb Det Noun\n",
    "- Same can be used in machine translation\n",
    "  - Beam search\n",
    "  - up-weight or down-weight based on the training data\n",
    "  - la maison bleue -> the blue house\n",
    "\n",
    "<img src=\"images/06_structuredPerceptronModified.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93614ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A* search\n",
    "- making things faster \n",
    "- the goal is similar to UCS but do it smarter and move towards the direction of goal state\n",
    "- but we dont have access to futurecost\n",
    "- but we have access to _h(s)-heuristic_, which is a estimate of _FutureCost(s)_\n",
    "- this heuristic helps me to be smarter when solving the algorithm\n",
    "\n",
    "<img src=\"images/06_heuristicFun.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e118b8f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- if i m at state s, and there is some other successor succ(s,a) and if I am trying to go $s_{end}$\n",
    "- h was my estimate to get to futureCost from successor to s-end minus the estimate to get to s-end from s\n",
    "- the h function penalizes from s to s-end, if we sway going away from the end state\n",
    "- depends on how good the h function is designed\n",
    "\n",
    "<img src=\"images/06_heuristicFun2.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c66b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Consistent heuristics\n",
    "- must satisfy triangle inequality\n",
    "  > - Cost'(s,a) >= Cost(s,a) + h(s') - h(s) >= 0\n",
    "  > - $h(s_{end}) = 0$\n",
    "\n",
    "<img src=\"images/06_heuConsistent.png\" width=400 height=400> \n",
    "$\\tiny{\\text{YouTube-Stanford-CS221-Dorsa Sadigh}}$   \n",
    "\n",
    "- The path of new cost - sum of new cost is equal to the sum of old cost minus some constant which is heuristic cost at $s_{0}$\n",
    "- The A star cost is just uniform cost with a constant\n",
    "- $A^{*}$ is correct only if it is consistent\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fcfa82",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Efficiency of A*\n",
    "- A* is more efficient is because it does not explore everything but explores in a directed manner\n",
    "- UCS explores all states s which satisfies \n",
    "  > PastCost(s) <= PastCost($s_{end}$)\n",
    "- A* explores explores less states and is smaller, because we are doing a directed search rather all states\n",
    "  > PastCost(s) <= PastCost($s_{end}$) - h(s)\n",
    "  - larger the h(s), better it is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7d944",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Few engineering tweaks/creating reverse problem\n",
    "- Relaxation\n",
    "- Easier search\n",
    "- Reversed relaxed problem\n",
    "- Independent subproblems"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
