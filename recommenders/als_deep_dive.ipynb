{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">This notebook is a copy of [Microsoft Recommender - Github repository](https://github.com/microsoft/recommenders/blob/main/examples/02_model_collaborative_filtering/als_deep_dive.ipynb) used for learning purposes. The contents of first section is unaltered and is rerun to generate results. The second section is extended with further experiments, learnings and analysis.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Collaborative Filtering (ALS) Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark MLlib provides a collaborative filtering algorithm that can be used for training a matrix factorization model, which predicts explicit or implicit ratings of users on items for recommendations.\n",
    "\n",
    "This notebook presents a deep dive into the Spark collaborative filtering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization algorithm\n",
    "\n",
    "### Matrix factorization for collaborative filtering problem\n",
    "\n",
    "Matrix factorization is a common technique used in recommendation tasks. Basically, a matrix factorization algorithm tries to find latent factors that represent intrinsic user and item attributes in a lower dimension. That is,\n",
    "\n",
    "$$\\hat r_{u,i} = q_{i}^{T}p_{u}$$\n",
    "\n",
    "where $\\hat r_{u,i}$ is the predicted ratings for user $u$ and item $i$, and $q_{i}^{T}$ and $p_{u}$ are latent factors for item and user, respectively. The challenge to the matrix factorization problem is to find $q_{i}^{T}$ and $p_{u}$. This is achieved by methods such as matrix decomposition. A learning approach is therefore developed to converge the decomposition results close to the observed ratings as much as possible. Furthermore, to avoid overfitting issue, the learning process is regularized. For example, a basic form of such matrix factorization algorithm is represented as below.\n",
    "\n",
    "$$\\min\\sum(r_{u,i} - q_{i}^{T}p_{u})^2 + \\lambda(||q_{i}||^2 + ||p_{u}||^2)$$\n",
    "\n",
    "where $\\lambda$ is a the regularization parameter. \n",
    "\n",
    "In case explict ratings are not available, implicit ratings which are usually derived from users' historical interactions with the items (e.g., clicks, views, purchases, etc.). To account for such implicit ratings, the original matrix factorization algorithm can be formulated as \n",
    "\n",
    "$$\\min\\sum c_{u,i}(p_{u,i} - q_{i}^{T}p_{u})^2 + \\lambda(||q_{i}||^2 + ||p_{u}||^2)$$\n",
    "\n",
    "where $c_{u,i}=1+\\alpha r_{u,i}$ and $p_{u,i}=1$ if $r_{u,i}>0$ and $p_{u,i}=0$ if $r_{u,i}=0$. $r_{u,i}$ is a numerical representation of users' preferences (e.g., number of clicks, etc.). \n",
    "\n",
    "### Alternating Least Square (ALS)\n",
    "\n",
    "Owing to the term of $q_{i}^{T}p_{u}$ the loss function is non-convex. Gradient descent method can be applied but this will incur expensive computations. An Alternating Least Square (ALS) algorithm was therefore developed to overcome this issue. \n",
    "\n",
    "The basic idea of ALS is to learn one of $q$ and $p$ at a time for optimization while keeping the other as constant. This makes the objective at each iteration convex and solvable. The alternating between $q$ and $p$ stops when there is convergence to the optimal. It is worth noting that this iterative computation can be parallelised and/or distributed, which makes the algorithm desirable for use cases where the dataset is large and thus the user-item rating matrix is super sparse (as is typical in recommendation scenarios). A comprehensive discussion of ALS and its distributed computation can be found [here](http://stanford.edu/~rezab/classes/cme323/S15/notes/lec14.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Mllib implementation\n",
    "\n",
    "The matrix factorization algorithm is available as `ALS` module in [Spark `ml`](https://spark.apache.org/docs/latest/ml-collaborative-filtering.html) for DataFrame or [Spark `mllib`](https://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) for RDD. \n",
    "\n",
    "* The uniqueness of ALS implementation is that it distributes the matrix factorization model training by using \"Alternating Least Square\" method. \n",
    "* In the training method, there are parameters that can be selected to control the model performance.\n",
    "* Both explicit and implicit ratings are supported by Spark ALS model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark ALS based MovieLens recommender\n",
    "\n",
    "In the following code, the MovieLens-100K dataset is used to illustrate the ALS algorithm in Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This notebook requires a PySpark environment to run properly. Please follow the steps in [SETUP.md](https://github.com/Microsoft/Recommenders/blob/master/SETUP.md#dependencies-setup) to install the PySpark environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.8.8 (default, Apr 13 2021, 12:59:45) \n",
      "[Clang 10.0.0 ]\n",
      "Pandas version: 1.4.1\n",
      "PySpark version: 3.2.1\n"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType\n",
    "\n",
    "from recommenders.datasets import movielens\n",
    "from recommenders.utils.spark_utils import start_or_get_spark\n",
    "from recommenders.evaluation.spark_evaluation import SparkRankingEvaluation, SparkRatingEvaluation\n",
    "from recommenders.tuning.parameter_sweep import generate_param_grid\n",
    "from recommenders.datasets.spark_splitters import spark_random_split\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"PySpark version: {}\".format(pyspark.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MOVIELENS_DATA_SIZE = \"100k\"\n",
    "\n",
    "COL_USER = \"UserId\"\n",
    "COL_ITEM = \"MovieId\"\n",
    "COL_RATING = \"Rating\"\n",
    "COL_PREDICTION = \"prediction\"\n",
    "COL_TIMESTAMP = \"Timestamp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    (\n",
    "        StructField(COL_USER, IntegerType()),\n",
    "        StructField(COL_ITEM, IntegerType()),\n",
    "        StructField(COL_RATING, FloatType()),\n",
    "        StructField(COL_TIMESTAMP, LongType()),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model hyper parameters - these parameters are selected with reference to the benchmarking results [here](http://mymedialite.net/examples/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANK = 10\n",
    "MAX_ITER = 15\n",
    "REG_PARAM = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of recommended items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize a Spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/14 22:52:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/03/14 22:52:42 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = start_or_get_spark(\"ALS Deep Dive\", memory=\"16g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is read from csv into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4.81k/4.81k [00:00<00:00, 7.91kKB/s]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfs = movielens.load_spark_df(spark=spark, size=MOVIELENS_DATA_SIZE, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|UserId|MovieId|Rating|Timestamp|\n",
      "+------+-------+------+---------+\n",
      "|   196|    242|   3.0|881250949|\n",
      "|   186|    302|   3.0|891717742|\n",
      "|    22|    377|   1.0|878887116|\n",
      "|   244|     51|   2.0|880606923|\n",
      "|   166|    346|   1.0|886397596|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is then randomly split by 80-20 ratio for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_train, dfs_test = spark_random_split(dfs, ratio=0.75, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a movielens model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that Spark ALS model allows dropping cold users to favor a robust evaluation with the testing data. In case there are cold users, Spark ALS implementation allows users to drop cold users in order to make sure evaluations on the prediction results are sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/14 22:53:17 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/03/14 22:53:17 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "22/03/14 22:53:18 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "als = ALS(\n",
    "    maxIter=MAX_ITER, \n",
    "    rank=RANK,\n",
    "    regParam=REG_PARAM, \n",
    "    userCol=COL_USER, \n",
    "    itemCol=COL_ITEM, \n",
    "    ratingCol=COL_RATING, \n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "model = als.fit(dfs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction with the model\n",
    "\n",
    "The trained model can be used to predict ratings with a given test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_pred = model.transform(dfs_test).drop(COL_RATING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the prediction results, the model performance can be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chandrasingh/opt/anaconda3/envs/reco/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score = 0.9672850377390322\n",
      "MAE score = 0.7520024463135003\n",
      "R2 score = 0.2606446451514729\n",
      "Explained variance score = 0.265904981685646\n"
     ]
    }
   ],
   "source": [
    "evaluations = SparkRatingEvaluation(\n",
    "    dfs_test, \n",
    "    dfs_pred,\n",
    "    col_user=COL_USER,\n",
    "    col_item=COL_ITEM,\n",
    "    col_rating=COL_RATING,\n",
    "    col_prediction=COL_PREDICTION\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"RMSE score = {}\".format(evaluations.rmse()),\n",
    "    \"MAE score = {}\".format(evaluations.mae()),\n",
    "    \"R2 score = {}\".format(evaluations.rsquared()),\n",
    "    \"Explained variance score = {}\".format(evaluations.exp_var()),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oftentimes ranking metrics are also of interest to data scientists. Note usually ranking metrics apply to the scenario of recommending a list of items. In our case, the recommended items should be different from those that have been rated by the users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cross join of all user-item pairs and score them.\n",
    "users = dfs_train.select(COL_USER).distinct()\n",
    "items = dfs_train.select(COL_ITEM).distinct()\n",
    "user_item = users.crossJoin(items)\n",
    "dfs_pred = model.transform(user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the ambiguous col exception\n",
    "dfs1 = dfs_pred.alias(\"pred\")\n",
    "dfs2 = dfs_train.alias(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 473:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|UserId|MovieId|prediction|\n",
      "+------+-------+----------+\n",
      "|     1|     46|  3.718766|\n",
      "|     1|    255| 2.1994865|\n",
      "|     1|    284| 2.9902596|\n",
      "|     1|    285|  4.315481|\n",
      "|     1|    318| 4.2022877|\n",
      "|     1|    329|  3.364408|\n",
      "|     1|    335|  2.745156|\n",
      "|     1|    353| 3.8310368|\n",
      "|     1|    371|  2.312728|\n",
      "|     1|    372| 4.1308403|\n",
      "|     1|    381| 3.6213713|\n",
      "|     1|    391| 2.5517013|\n",
      "|     1|    409|  2.576128|\n",
      "|     1|    413| 2.8441556|\n",
      "|     1|    417| 2.5588927|\n",
      "|     1|    440| 0.5752399|\n",
      "|     1|    449| 3.1248236|\n",
      "|     1|    463|  4.198607|\n",
      "|     1|    480|  4.484024|\n",
      "|     1|    488| 4.0404654|\n",
      "+------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove seen items.\n",
    "# dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "#     dfs_train.alias(\"train\"),\n",
    "#     (dfs_pred[COL_USER] == dfs_train[COL_USER]) & (dfs_pred[COL_ITEM] == dfs_train[COL_ITEM]),\n",
    "#     how='outer'\n",
    "# )\n",
    "dfs_pred_exclude_train = dfs1.join(dfs2,\n",
    "    (dfs1[COL_USER] == dfs2[COL_USER]) & (dfs1[COL_ITEM] == dfs2[COL_ITEM]),\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "dfs_pred_final = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.Rating\"].isNull()) \\\n",
    "    .select('pred.' + COL_USER, 'pred.' + COL_ITEM, 'pred.' + \"prediction\")\n",
    "\n",
    "dfs_pred_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chandrasingh/opt/anaconda3/envs/reco/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@k = 0.043266171792152724\n",
      "Recall@k = 0.01443145319982623\n",
      "NDCG@k = 0.03709733077247258\n",
      "Mean average precision = 0.0033258968835808275\n"
     ]
    }
   ],
   "source": [
    "evaluations = SparkRankingEvaluation(\n",
    "    dfs_test, \n",
    "    dfs_pred_final,\n",
    "    col_user=COL_USER,\n",
    "    col_item=COL_ITEM,\n",
    "    col_rating=COL_RATING,\n",
    "    col_prediction=COL_PREDICTION,\n",
    "    k=K\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Precision@k = {}\".format(evaluations.precision_at_k()),\n",
    "    \"Recall@k = {}\".format(evaluations.recall_at_k()),\n",
    "    \"NDCG@k = {}\".format(evaluations.ndcg_at_k()),\n",
    "    \"Mean average precision = {}\".format(evaluations.map_at_k()),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune the model\n",
    "\n",
    "Prediction performance of a Spark ALS model is often affected by the parameters\n",
    "\n",
    "|Parameter|Description|Default value|Notes|\n",
    "|-------------|-----------------|------------------|-----------------|\n",
    "|`rank`|Number of latent factors|10|The larger the more intrinsic factors considered in the factorization modeling.|\n",
    "|`regParam`|Regularization parameter|1.0|The value needs to be selected empirically to avoid overfitting.|\n",
    "|`maxIters`|Maximum number of iterations|10|The more iterations the better the model converges to the optimal point.|\n",
    "\n",
    "It is always a good practice to start model building with default parameter values and then sweep the parameter in a range to find the optimal combination of parameters. The following parameter set is used for training ALS models for comparison study purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    \"rank\": [10, 15, 20],\n",
    "    \"regParam\": [0.001, 0.1, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a dictionary for each parameter combination which can then be fed into model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = generate_param_grid(param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train models with parameters specified in the parameter grid. Evaluate the model with, for example, the RMSE metric, and then record the metrics for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chandrasingh/opt/anaconda3/envs/reco/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rmse_score = []\n",
    "\n",
    "for g in param_grid:\n",
    "    als = ALS(        \n",
    "        userCol=COL_USER, \n",
    "        itemCol=COL_ITEM, \n",
    "        ratingCol=COL_RATING, \n",
    "        coldStartStrategy=\"drop\",\n",
    "        **g\n",
    "    )\n",
    "    \n",
    "    model = als.fit(dfs_train)\n",
    "    \n",
    "    dfs_pred = model.transform(dfs_test).drop(COL_RATING)\n",
    "    \n",
    "    evaluations = SparkRatingEvaluation(\n",
    "        dfs_test, \n",
    "        dfs_pred,\n",
    "        col_user=COL_USER,\n",
    "        col_item=COL_ITEM,\n",
    "        col_rating=COL_RATING,\n",
    "        col_prediction=COL_PREDICTION\n",
    "    )\n",
    "\n",
    "    rmse_score.append(evaluations.rmse())\n",
    "\n",
    "rmse_score = [float('%.4f' % x) for x in rmse_score]\n",
    "rmse_score_array = np.reshape(rmse_score, (len(param_dict[\"rank\"]), len(param_dict[\"regParam\"]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_df = pd.DataFrame(data=rmse_score_array, index=pd.Index(param_dict[\"rank\"], name=\"rank\"), \n",
    "                       columns=pd.Index(param_dict[\"regParam\"], name=\"reg. parameter\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='reg. parameter', ylabel='rank'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi0UlEQVR4nO3dd3hUVf7H8fd3Sgq9GVowYAHBhkpYy6q4KtiwLdYVVxEQRdFVQUXUtYMsKBbUwGLhByxWBGzYsKyFIqGZREGkSe8ESDIz5/fHDFkCJERhMpD7eT3PPMzcc+6935Ob+eTkzuXGnHOIiEjl50t0ASIiUjEU+CIiHqHAFxHxCAW+iIhHKPBFRDwikOgCSrPm/NN1+dABrP7H8xJdgvxBG/q1S3QJsheqPjDKSmvTDF9ExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hEKfBERj1Dgi4h4hAJfRMQjFPgiIh6hwBcR8QgFvoiIRyjwRUQ8QoEvIuIRCnwREY9Q4IuIeIQCX0TEIxT4IiIeocAXEfEIBb6IiEco8EVEPEKBLyLiEQp8ERGPUOCLiHiEAl9ExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hEKfBERjwgkuoDKoOptd5PU9iQi69exoef1u7QHTzyFKtfcAC4C4TD5Wc8R+nF2tO2EtlTtfiv4fGyb9B7b3hgNQNKf25F69XX4m2Sw4R89CM/Lq9AxeUmH9u0YPPhh/D4fI14ew5MDny/RXqtWTYYPG8Qhh2RQsK2Art3vZO7cPNLTG/HKiCHUb3AQkUiE4cNH8exz/wbgmGNaMfS5/lStVoWFC5fQ+dpb2LRpcyKGV6kldexGoPlxuPyNbH3xnl3a/c1PIOmMTjjnIBKm8KORRBb/FG1MrkJyx2740tLBOQomZBFZMg9f/YNJOr8LFkwhsmEVBW8PhcKtFTyy+NAMfx8o+OQDNj7Qu9T2ouwf2HBLFzbc2pXNTw+gWq9YX5+PqjfdzsYH+7D+pr+TfNqZ+JtkABBeuIBNj91PaM7MihiCZ/l8Pp4Z8hgXdLyGo489gyuuuJiWLQ8v0efeu29l5sy5HH/C2VzX5TaeGvQwAKFQiN59HuLoY9pxyp87ctNN1xWv+9KLA+l73+Mcd/xZjBv3AXfdeVOFj80LQjO/YtuoJ0ttDy+Yw9aX7mVbVl8KxmeR3LFbcVvSOZ0Jz5/J1qG92frSvURW/RZdfkFXCj/9D1tfuodw7jSCJ58f93FUFAX+PhCaOwu3aVPpHbb9b3ZgKam42PNA85aEf1tKZPkyCIUo+PIzgif+GYDw4oVEli6OY9UC0DbzOObP/5UFCxZRVFTE66+/y4UdO5To07Jlcz777GsA8vLmk5GRTlpaPZYvX8mM7DkAbN6cT27uzzRu1ACAFs0P5cuvvgPgk0+/4pJLzqvAUXlHZFEubmsZvzkVFRQ/taRkcLF3X1Iq/oOPIDRjcmxDYSjYAoCvXiMiC3MBCP8ym0DLtvEoPSHiEvhmVtPM+ptZrpmtiT1yYstqxWOf+7ukk06l1ouvUf2f/cl/egAAvrr1iKxeWdwnsnoV/rr1ElWiJzVq3IDFS34rfr1k6TIaxUJ7u1mzf+SSi6OBndmmNRkZ6aQ3bliiT0ZGOq2PPYrvp8wAYO7cPDp2bA9Ap79eQJP0RvEchpTB36INqTcPJOWq3hRMyALAVzsNt2UTSRfeSEq3x0i6oCsEkwGIrFyMv/kJ0XVb/QmrUSdhte9r8Zrhvw6sA9o55+o65+oCZ8SWvRGnfe7XCr/9ivU9rmXTI/eR2rlLdKHZLv3cLksknmx3x8CVPAoDnnyOWrVrMm3qJHr27MKM7DmEwuHi9qpVq/D62GHccdeDxefpu3a/g5t7XMf3331A9epVKSwsiu9ApFThvGlsHdqbbWOfIqndZdGFPh++hk0JTf+EbcPug6ICgqd0BKBgfBbBzLNJ6foolpQK4VACq9+34vWhbVPn3IAdFzjnlgMDzKxLaSuZWXegO8Cgow7n7wc3LK3rASs0dxb+Bo2xGjWJrF6Fr15acZuv3kFE1qxOYHXes3TJshKz7/TGDVm2bEWJPps2baZrtzuKX8/76TsWLFgEQCAQ4I2xwxgz5h3GjfuguE9e3nzOPf9qAA4//BDOO/fMeA5DyiGyKBernQap1XAb1+I2riWydD4AoZwpxYHv1ixj26j+AFidBvgPb52okve5eM3wF5pZHzOrv32BmdU3s7uBUk9MO+eynHNtnHNtKlPY+xo2Ln7uP/RwLBDAbdxA6Kdc/I3T8dVvAIEAyaf9haLv/5vASr1n6rRsDjusGU2bNiEYDHL55RcxYeKkEn1q1qxBMBgE4IYuV/PV198Xz+SHZQ0iJ3ceTw/JKrHOQQfVBaK/QfS99zZeyhpZAaORnVnt4gjC16Ap+AOwdTMufwNu4xqsbjRn/M2OJLJqabRjlRrb1yZ46sWEpn9asUXHUbxm+FcA9wBfmNn2KewKYDxwWZz2mTDV+jxA8OjWWI2a1Hr1DbaOejn6jQUUfDCepFNOI/kvHSAcwhUUsmnAQ9EVI2HyX3iaGo/8C3w+Cj5+n/CiX4HoOf8qPXrhq1mLGv/sT+iXeWwq40og+WPC4TC33d6P998bjd/n45VXx/Ljjz/RvVtnALKGjaTlEYfz8oghhCNhcnJ+olv3uwA45eRMOl/TiVmzf2Ta1OgPifvv788HH37GlVdczE03XQfAuHHv88qrYxMyvsou+dKe+DJaYlWqk3r7sxRNfrP4vRea/imBlpkEjjkVFwlDqJCCt54tXrfwg9dIvuRmzB8gsm4lBeNfAiBw1EkEM8+ObiN3KqHsLyp+YHFiO5+vjPsOza53zr28p35rzj9dp7MPYPU/npfoEuQP2tCvXaJLkL1Q9YFRu34wFZOIyzIfSsA+RUQ8Ly6ndMxsVmlNQP1S2kREJI7idQ6/PtCB6GWYOzLgmzjtU0REyhCvwJ8IVHPOZe/cYGaT47RPEREpQ1wC3zl3QxltV8djnyIiUjbdS0dExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hEKfBERj1Dgi4h4hAJfRMQjFPgiIh6hwBcR8QgFvoiIRyjwRUQ8QoEvIuIRCnwREY9Q4IuIeIQCX0TEIxT4IiIeocAXEfEIBb6IiEco8EVEPEKBLyLiEQp8ERGPUOCLiHiEAl9ExCMU+CIiHqHAFxHxiECiCyhN9ecHJboE2QvW/KJElyAiO9EMX0TEIxT4IiIeocAXEfEIBb6IiEco8EVEPEKBLyLiEQp8ERGPUOCLiHiEAl9ExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hEKfBERj1Dgi4h4hAJfRMQjFPgiIh6hwBcR8QgFvoiIRyjwRUQ8QoEvIuIRCnwREY9Q4IuIeIQCX0TEIxT4IiIeUa7AN7Pk3Syrs+/LERGReCnvDP9tMwtuf2FmDYGP41OSiIjEQ3kDfxzwhpn5zawp8BFwb7yKEhGRfS9Qnk7OuWFmlkQ0+JsCNzrnvoljXSIiso+VGfhmdseOL4EmQDZwopmd6JwbHMfaRERkH9rTDL/6Tq/fKWW5p90/KIsvv59BnVo1eCdrwC7tU2f+SK9/DqZxg4MAOPOUTG665lIAvp46kwEvjiQcjnDpue3oesWFAOTO/5VHnhlBQWERfr+ffrdcz9FHHFpxg6rk2rdvx+DBD+P3+Rjx8hgGDny+RHutWjUZNmwQhx6SwbZtBXTrfidz5+aRnJzM55+9RXJyMv6An7fffo+HHx4EQO3atRg96gUyMpqwcOFirrq6B+vXbyAQCJD10r847rij8AcC/N//vcmTTz6XiGFXOkkduxFofhwufyNbX7xnl3Z/8xNIOqMTzjmIhCn8aCSRxT9FG5OrkNyxG760dHCOgglZRJbMw1f/YJLO74IFU4hsWEXB20OhcGsFjyw+ygx859xDFVXIgeyi9qdy1YVnc9/AF0vtc/xRLXj+kd4lloXDER57/hWynriXBvXqcOWt93PGicdzaEY6g4ePocc1l3JqZmu+nJLN4H+P4eWB/eI9FE/w+Xw8M+Qxzj3vKpYsWcZ3377PxImTyMn5ubjPPXffysyZc7nssq60aHEozwx5nA7nXEFBQQFnt7+c/PwtBAIBvpj8Dh99+DnfT/mBPn168tnnXzNw4PP07t2TPn160rfv43TqdAFJyUkcd/xZpKamMGvmZMaOHcfChUsS+FWoHEIzvyI09WOSL+6x2/bwgjls/Wk6AJbWhJROvdg6NPo+TDqnM+H5Myl4cwj4/BCMXoyYdEFXCj8ZTWRhLoHWpxM8+XyKJr9ZMQOKs/JeltnczLLMbJKZfbb9UUb/c3Z4XtPM/m1ms8xstJnV3xeF70/aHN2SmtWr/e71ZufN5+BG9WnSMI1gMMC57U7k829j35xm5OdHZxWb87dwUJ1a+7JkT2ubeRzz5//KggWLKCoqYuzr79KxY4cSfVq2bM7nn30NQF7efDIy0klLqwdAfv4WAILBAMFgMDp7BDp27MDIkW8AMHLkG1x4YfRt4JyjatUq+P1+UlNTKSwqYuPGzRUy1sousigXt7WMr2VRQfFTS0qG2LEiKRX/wUcQmjE5tqEwFESPq69eIyILcwEI/zKbQMu28Sg9Icp7lc4bwAygH9B7h0dpHt/h+SBgGdARmAq89PvLPPDNzJnHX3vcS4/7BjDv1+jMbuWatTQ4qG5xn/r16rBi9ToA7u7RmUHDx3DW325l0LDR3N7lioTUXRk1atyAJUt+K369dOkyGjdqUKLPrNk/cvHF5wGQ2aY1GRnppDduCER/Q5g2dRK/LZ3FJ59+yZSpMwCon1aP5ctXArB8+UrSYsf2rbfeIz9/C4sXzeCX+VN4avCLrFu3Pt7DlBh/izak3jyQlKt6UzAhCwBf7TTclk0kXXgjKd0eI+mCrsUz/MjKxfibnxBdt9WfsBqV578clTfwQ865F5xzU5xz07c/yrluG+dcP+fcQufcU0Sv8tktM+tuZtPMbNrw0W+Xc/P7v5aHNWXSyCG89eITXH1RB257KPpZ9/bJxo7MDICxEz+hz43X8MmoZ+l94zU8MHhYRZZcqW3/Gu/I7XQwnnzyOWrXrsm0qZPo2bML2dlzCIXDAEQiEdpktqdpszZktjmOI49sUeb+2ma2JhIOc3DG8Rze/ERu/8eNNGt28L4bkJQpnDeNrUN7s23sUyS1uyy60OfD17ApoemfsG3YfVBUQPCUjgAUjM8imHk2KV0fxZJSIRxKYPX7VnkDf4KZ3WxmDc2szvZHGf3TzOwOM7sTqGEl32Gl7tM5l+Wca+Oca9P16kvLWdr+r1rVKlRJTQHgtLatCYXDrNuwifr16rB81ZrifitWryWtbi0Axn/8FWf9OROADqf9iTk/za/wuiurpUuWkZ7eqPh148YN+W3ZihJ9Nm3aTNdud9Amsz3XXd+LevXqsmDBohJ9NmzYyBdffkP79u0AWLFyNQ0apAHQoEEaK2PH9sorL+GjSZMJhUKsWrWGb7+ZygknHBvHEcruRBblYrXTILUabuNa3Ma1RJZG31ehnCn4GjYFwK1ZxrZR/dk2vB+hOd8QWbcygVXvW+UN/L8TPYXzDTA99phWRv9hRK/kqQa8CtQDMLMGRC/r9JTVa9cXzyBn584nEnHUqlGNo1ocwsKly1myfCVFRSE+mPwd7U6M/ip5UN3aTJuVA8D32XM5eKdTDvLHTZ2WzWGHNaNp0yYEg0GuuPwiJk6cVKJPzZo1CAaj/7n8hi5X8/XX37Np02bq1atDzZo1AEhJSeHMv5xKXl40NCZOmETnztEZZOfOlzFhwkcALFq8lDPanQJAlSqptP3T8eTlzauQsXqd1f7fR4a+Bk3BH4Ctm3H5G3Ab12B1o6fp/M2OJLJqabRjlRrb1yZ46sWEpn9asUXHUXn/41Wz37PR0q7ucc4tN7PPf8+2DgR9nniOqbNyWL9hE2f+7RZ6du5EKBT9NfDyC85i0ldTeH3iJ/j9flKSgwy89xbMjIDfT9+e19Gj7wDCkQiXtD+dw5qmA/DP27vS/4XXCIcjJCcFefD2rokcYqUSDoe57fZ+vPfeaPw+H6+8OpYff/yJ7t06A5A1bCQtjzicESOGEI6Eycn5ie7d7wKgYcP6jPj30/j9Pszn4803J/D++58A8OTA5xkz+kWuv+4qFi9eypVX3QjACy+8wvDhT5Gd/RlmxquvjmX27JzEDL6SSb60J76MlliV6qTe/mz0ahp/NNZC0z8l0DKTwDGn4iJhCBVS8NazxesWfvAayZfcjPkDRNatpGB89OPFwFEnEcw8O7qN3KmEsr+o+IHFie187rLUjmZHAa2AlO3LnHOv/e4dmi1yzu3xBGbhr9PKV5jsl6o2vyjRJcgftL5fu0SXIHuh6gOjdv2QKqZcM3wzexBoRzTw3wfOBb4Gdhv4ZjartE0Ble6yTBGRA0G5Ah/oBBwLzHDOXR+7ln54Gf3rAx2AdTstN6KfA4iISAUrb+Bvc85FzCxkZjWAlcAhZfSfCFRzzmXv3GBmk393lSIistf2GPixSypnmVktolffTAc2A1NKW8c5d0MZbVf//jJFRGRv7THwnXPOzFo759YDL5rZh0AN51xp5+lFRGQ/VN7r8L8zs0wA59yvCnsRkQNPec/hnwHcaGYLgXyiH74659wxcatMRET2qfIG/rlxrUJEROKuvP/TdmG8CxERkfgq7zl8ERE5wCnwRUQ8QoEvIuIRCnwREY9Q4IuIeIQCX0TEIxT4IiIeocAXEfEIBb6IiEco8EVEPEKBLyLiEQp8ERGPUOCLiHiEAl9ExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hEKfBERj1Dgi4h4hAJfRMQjAokuoDRWrU6iS5C94BJdgIjsQjN8ERGPUOCLiHiEAl9ExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hEKfBERj1Dgi4h4hAJfRMQjFPgiIh6hwBcR8QgFvoiIRyjwRUQ8QoEvIuIRCnwREY9Q4IuIeIQCX0TEIxT4IiIeocAXEfEIBb6IiEco8EVEPEKBLyLiEQp8ERGPUOCLiHiEAl9ExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDwikOgCKoN+jw/my/9OoU7tWoz7vxd3aZ/ywyx63fMQjRs2AOCs00/mpi5/Y9mKVfR95F+sXrsOnxmdLjqXzpdfDEDuz7/wyMBn2bJ1G40apjHgwT5Uq1q1IodVqXVo347Bgx/G7/Mx4uUxPDnw+RLttWrVZPiwQRxySAYF2wro2v1O5s7NIz29Ea+MGEL9BgcRiUQYPnwUzz73bwCOPfZIhj7Xn+SUZEKhELfe2pep07I568xTeeyxviQlBSksLOKeex7l88n/TcSwK52kjt0IND8Ol7+RrS/es0u7v/kJJJ3RCeccRMIUfjSSyOKfoo3JVUju2A1fWjo4R8GELCJL5uGrfzBJ53fBgilENqyi4O2hULi1gkcWH+acS3QNu1W0+pf9s7DdmJY9myqpqfR95F+lBv4rY95i6MCHSixftXotq9aspVWLw8jP38LlN/TimSfu59BmGVxxQy/uuqUrmccdw9sTP2Lpbyu4tfu1FTWkvZba6NREl1Aqn89HztyvOOe8q1iyZBnfffs+13S+mZycn4v7DHiiH5vz83nk0ado0eJQnh3yOO3PuYIGDdJo2CCNGdlzqFatKlO+/5C/dupCTs7PfPDeaIY8M4wPP/qcc8/5C3fdeRNnnn0ZrVsfyYoVq1m2bAVHHtmC9yeOIqNZmwR+Bcq2oV+7RJdQbr6Dj4DCbSRf3GO3gU8wGYoKALC0JqR06sXWob0BSLroRiKL8gjNmAw+f7RvwRZSbniYwk9GE1mYS6D16Vitgyia/GYFjmrvVH1glJXWFpdTOmZW08z6m1muma2JPXJiy2rFY5+J1Kb10dSsUf13r3dQvTq0anEYAFWrVuGQjCasWLUGgF8XLaFN66MBOCnzeD7+4ut9V7DHtc08jvnzf2XBgkUUFRXx+uvvcmHHDiX6tGzZnM8+i37N8/Lmk5GRTlpaPZYvX8mM7DkAbN6cT27uzzRuFP3NzTlH9dj3QY2a1flt2QoAsrPnsiz2fO7cPFJSUkhKSqqQsVZ2kUW5uK2bS+8QC3sAS0qG7RPcpFT8Bx8RDXuASBgKtgDgq9eIyMJcAMK/zCbQsm08Sk+IeJ3Dfx1YB7RzztV1ztUFzogteyNO+9yvzZyTw6V/v5ked97PvF8W7tK+dNkKcn6ezzFHtgDgsEOa8vnX3wEw6fOvWL5idYXWW5k1atyAxUt+K369ZOkyGsVCe7tZs3/kkovPAyCzTWsyMtJJb9ywRJ+MjHRaH3sU30+ZAcAddz3IgCf6sWD+VJ7sfz/39Xtil31feun5ZGfPobCwcF8PS0rhb9GG1JsHknJVbwomZAHgq52G27KJpAtvJKXbYyRd0DU6wwciKxfjb35CdN1Wf8Jq1ElY7ftavAK/qXNugHNu+fYFzrnlzrkBwMFx2ud+q1WLQ/n4rVd5+9WhXP3XjvS69+ES7Vu2bOUf9z3K3b1uLD5P/0jffzDmrQlc3uVW8rdsJRjUxy37itmuv/HufGpzwJPPUat2TaZNnUTPnl2YkT2HUDhc3F61ahVeHzuMO+56kE2bojPMG7tfy529/0mzQzO5s/dDDHtpUIlttmrVnCce68tNPe+Ow6ikNOG8aWwd2pttY58iqd1l0YU+H76GTQlN/4Rtw+6DogKCp3QEoGB8FsHMs0np+iiWlArhUAKr37fiFfgLzayPmdXfvsDM6pvZ3cDi0lYys+5mNs3Mpg1/bUycSqt41apWpUqVVABOO7ktoVCIdes3AFAUCnH7fY9yfvszOLvdKcXrHJLRhGFPP87rI57lvLNOp8lOs0v545YuWUaT9EbFr9MbNyw+5bLdpk2b6drtDtpktue663txUL26LFiwCIBAIMAbY4cxZsw7jBv3QfE613a+jHfeeR+AN9+cQGZm6+K2xo0b8uYb/+b6Lrfxy25+w5P4iyzKxWqnQWo13Ma1uI1riSydD0AoZwq+hk0BcGuWsW1Uf7YN70dozjdE1q1MYNX7VrwC/wqgLvCFma0zs7XAZKAOcHlpKznnspxzbZxzbbpee1WcSqt4q9esLZ5Bzv4xj4hz1KpZA+ccDzzxNIdkNOHvV15aYp0169YDEIlEeOnV/3B57PSC7L2p07I57LBmNG3ahGAwyOWXX8SEiZNK9KlZswbBYBCAG7pczVdff188kx+WNYic3Hk8PSSrxDq/LVvB6aedBMBfzvgzP89bULyt8e++xn39nuCbb6fFe3iyA6tdPOfE16Ap+AOwdTMufwNu4xqsbnQi5W92JJFVS6Mdq9TYvjbBUy8mNP3Tii06juJ2lY6ZHQGkA9855zbvsPwc59yHe1r/QLpKp/eD/Zk6Yxbr12+kbp1a3HxDZ0Kh6K+BV1xyPqPfHM/Yd97DH/CTkpRE717dOe7oVvwwcw7X3tybww9tis+iP3tvu/HvnHZyW0a+Po7/vD0RiF7GeXuP63d7KmJ/tT9fpQNw7jl/YdCgh/D7fLzy6lie6P8M3bt1BiBr2EhO/NMJvDxiCOFImJycn+jW/S7Wr9/AKSdn8sXkccya/SORSPRb9P77+/PBh59xysmZDB78MIFAgIJt27jl1r78MGM2fe+9jbv73FL8AwDg3POuYlXsA/r9zYF0lU7ypT3xZbTEqlTH5W+MXk3jj57+DE3/lODJFxA45lRcJAyhQgo/Hl18WaavfgZJHbti/gCRdSspGP8SbNtCoG0HgplnR7eRO5WiT8cmbHx/RFlX6cQl8M2sF9ATyAFaA7c5596Ntf3gnDt+T9s4kAJfdrW/B76U7kAKfNlVWYEfr08CuwEnOOc2m1lT4E0za+qcGwIcONNUEZFKJF6B799+Gsc596uZtSMa+hko8EVEEiJeH9ouN7PW21/Ewv8CoB5wdJz2KSIiZYhX4F8LLN9xgXMu5Jy7FjgtTvsUEZEyxOWUjnNuSRltumuUiEgC6PbIIiIeocAXEfEIBb6IiEco8EVEPEKBLyLiEQp8ERGPUOCLiHiEAl9ExCMU+CIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hEKfBERj1Dgi4h4hAJfRMQjFPgiIh6hwBcR8QgFvoiIRyjwRUQ8QoEvIuIRCnwREY9Q4IuIeIQCX0TEIxT4IiIeocAXEfEIBb6IiEeYcy7RNXiSmXV3zmUlug75Y3T8DlxePnaa4SdO90QXIHtFx+/A5dljp8AXEfEIBb6IiEco8BPHk+cQKxEdvwOXZ4+dPrQVEfEIzfBFRDxCgS8i4hEK/H3AzM4xszwzm2dm9+ym3czsmVj7LDM7fk/rmtllZjbXzCJm1qaixiL/U47jeoSZfWtmBWZ2VyJqlN0zsxFmttLM5pTSXup7sjJT4O8lM/MDzwPnAq2Aq8ys1U7dzgUOjz26Ay+UY905wKXAl/Eeg+yqnMd1LdAL+FcFlyd79gpwThntu31PVnYK/L3XFpjnnPvFOVcI/Ae4aKc+FwGvuajvgFpm1rCsdZ1zOc65vIobhuxkj8fVObfSOTcVKEpEgVI659yXRH8gl6a092SlpsDfe42BxTu8XhJbVp4+5VlXEkPHpnLz5PFV4O89282yna91La1PedaVxNCxqdw8eXwDiS6gElgCNNnhdTrwWzn7JJVjXUmM8hxXOXB58vhqhr/3pgKHm1kzM0sCrgTG79RnPHBt7MqAE4ENzrll5VxXEkPHpnIr7T1ZqWmGv5eccyEzuwX4CPADI5xzc82sR6z9ReB94DxgHrAFuL6sdQHM7BLgWeAg4D0zy3bOdajY0XlXeY6rmTUApgE1gIiZ3Q60cs5tTFTdEmVmY4B2QD0zWwI8CASh7PdkZadbK4iIeIRO6YiIeIQCX0TEIxT4IiIeocAXEfEIBb6IiEco8EX2Q2bWN9E1SOWjyzLlgGFmRvR7NpLoWiB6R03nXDhO297snKu2v9QjlYNm+LJfM7OmZpZjZkOBH4AmZtbbzKbG7mP+0A597zezXDP72MzG7Oke9WZ2nZm9a2Yfxu57/+AObePMbHrsbxJ032H5ZjN72My+B04yswditcwxs6zYDyXMbLKZPWVmX8bqzzSzt83sZzN7dIftXWNmU8ws28xeMjO/mfUHUmPLRpXWb3f17JMvulRezjk99NhvH0BTIAKcGHvdnugfoTaiE5aJwGlAGyAbSAWqAz8Dd+1h29cBy4C6sfXmAG1ibXVi/25fXjf22gGX77CNOjs8Hwl0jD2fDAyIPb+N6H1aGgLJRO/jUhdoCUwAgrF+Q4FrY88377DdsvqVqEcPPcp66NYKciBY6KL3LIdo4LcHZsReVyP6RyyqA+8657YCmNmEcm77Y+fcmtg6bwN/Jnq7hF6x21tA9CZbhwNrgDDw1g7rn2FmfYAqQB1gLtFwhv/de2c2MNfF7tViZr/Etvln4ARgauwXg1Rg5W5qPLOMfjvXI1IqBb4cCPJ3eG7AE865l3bsYGb/+IPb3vlDLGdm7YCzgJOcc1vMbDKQEmvf5mLnyc0shehsu41zbrGZ/XOHfgAFsX8jOzzf/joQG8urzrl791BjWf2K6xHZE53DlwPNR0AXM6sGYGaNzSwN+BroaGYpsbbzy7m9s82sjpmlAhcD/wVqAutiYX8EcGIp624P99WxfXb6nWP5FOgUq59YHRmxtiIzC5ajn0i5aYYvBxTn3CQzawl8Gzu9sRm4xjk31czGAzOBhURPy2wA2OnOpTv7mui598OA0c65aWY2G+hhZrOAPOC73ayHc269mQ0jesrmV6K3VP49Y/nRzPoBk8zMR/RPJfaM1Z8FzDKzH5xzfyujn0i56bJMqTTMrJpzbrOZVSH6x9+7O+d+KKP/dURPx9xSUTWKJJJm+FKZZJlZK6KnWl4tK+xFvEgzfBERj9CHtiIiHqHAFxHxCAW+iIhHKPBFRDxCgS8i4hH/D4sO25yVQpwxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.heatmap(rmse_df, cbar=False, annot=True, fmt=\".4g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculated RMSE scores can be visualized to comparatively study how model performance is affected by different parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from this visualization that RMSE first decreases and then increases as rank increases, due to overfitting. When the rank equals 20 and the regularization parameter equals 0.1, the model achieves the lowest RMSE score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top K recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top k for all users (items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_rec = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2169:==============================================>     (90 + 10) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserId|     recommendations|\n",
      "+------+--------------------+\n",
      "|     1|[{1536, 3.891199}...|\n",
      "|     3|[{1536, 3.1063848...|\n",
      "|     6|[{1536, 3.7354305...|\n",
      "|    12|[{1536, 4.4471893...|\n",
      "|    13|[{1536, 3.3997421...|\n",
      "|    16|[{1536, 4.5658073...|\n",
      "|    20|[{1536, 3.3140035...|\n",
      "|    22|[{1536, 3.7392457...|\n",
      "|    26|[{1536, 3.1729913...|\n",
      "|    27|[{1536, 3.4825768...|\n",
      "+------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfs_rec.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top k for a selected set of users (items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = dfs_train.select(als.getUserCol()).distinct().limit(3)\n",
    "\n",
    "dfs_rec_subset = model.recommendForUserSubset(users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|UserId|     recommendations|\n",
      "+------+--------------------+\n",
      "|   471|[{1536, 3.3287532...|\n",
      "|   463|[{1536, 3.1125836...|\n",
      "|   148|[{1536, 3.9075735...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_rec_subset.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run-time considerations for top-k recommendations\n",
    "\n",
    "It is worth noting that usually computing the top-k recommendations for all users is the bottleneck of the whole pipeline (model training and scoring) of an ALS based recommendation system. This is because\n",
    "* Getting the top k from all user-item pairs requires a cross join which is usually very computationally expensive. \n",
    "* Inner products of user-item pairs are calculated individually instead of leveraging matrix block multiplication features which are available in certain contemporary computing acceleration libraries (e.g., BLAS).\n",
    "\n",
    "More details about possible optimizations of the top k recommendations in Spark can be found [here](https://engineeringblog.yelp.com/2018/05/scaling-collaborative-filtering-with-pyspark.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup spark instance\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Yehuda Koren, Robert Bell, and Chris Volinsky, \"Matrix Factorization Techniques for Recommender Systems\n",
    "\", ACM Computer, Vol. 42, Issue 8, pp 30-37, Aug., 2009.\n",
    "2. Yifan Hu, Yehuda Koren, and Chris Volinsky, \"Collaborative Filtering for Implicit Feedback Datasets\n",
    "\", Proc. IEEE ICDM, 2008, Dec, Pisa, Italy.\n",
    "3. Apache Spark. url: https://spark.apache.org/docs/latest/ml-collaborative-filtering.html\n",
    "4. Seaborn. url: https://seaborn.pydata.org/\n",
    "5. Scaling collaborative filtering with PySpark. url: https://engineeringblog.yelp.com/2018/05/scaling-collaborative-filtering-with-pyspark.html\n",
    "6. Matrix Completion via Alternating Least Square (ALS). url: http://stanford.edu/~rezab/classes/cme323/S15/notes/lec14.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My Learnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "- Before starting to learn, following actions need to be taken on a local mac laptop \n",
    "  1. Create virtual environment for setting up kernel for interactive computing using Anaconda Jupyter and not pollute existing environment\n",
    "  1. Setup ability to choose from multiple Java version\n",
    "  1. Setup PySpark  \n",
    "  1. Register environment variables with virtual environment and its associated ipykernel\n",
    "  1. Setup git recommenders locally and build using the local git copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- <div class=\"alert alert-warning\"> Check the active sh - bash or zsh, accordingly update ~/.bash_profile or ~/.zshrc</div>  \n",
    "\n",
    "> `$SHELL --version`  \n",
    "\n",
    "zsh 5.8 (x86_64-apple-darwin21.0)  \n",
    "- Renamed config.json to be able to switch to different venv without authentication hassle\n",
    "> `cd ~/.jupyter/`  \n",
    "> `mv jupyter_notebook_config.json jupyter_notebook_config.json.bkp`  \n",
    "- Create new venv\n",
    "> `python --version`\n",
    "3.8.8  \n",
    "> `conda create --name reco python=3.8.8`   \n",
    "> `conda activate reco`  \n",
    "- As a pre-requisite to installing the dependencies, if using Conda, make sure that Anaconda and the package manager Conda are both up to date\n",
    "> `conda update conda -n root`  \n",
    "> `conda install anaconda` since it is a new venv, otherwise `conda update anaconda`  \n",
    "> `pip install pyspark`  \n",
    "\n",
    "Successfully installed py4j-0.10.9.3 pyspark-3.2.1  \n",
    "- [How to install java on mac](https://stackoverflow.com/questions/24342886/how-to-install-java-8-on-mac)  \n",
    "> `brew tap adoptopenjdk/openjdk`  \n",
    "> `brew install --cask adoptopenjdk8`  \n",
    "- NOTE Spark requires Java version 8 or 11. We support Spark versions 3.0 and 3.1, but versions 2.4+ with Java version 8 may also work.\n",
    "> `brew install --cask adoptopenjdk11`  \n",
    "- If you want to install/manage multiple version then you can use 'jenv':  \n",
    "> `echo 'export PATH=\"$HOME/.jenv/bin:$PATH\"' >> ~/.bash_profile`  \n",
    "> `echo 'eval \"$(jenv init -)\"' >> ~/.bash_profile`  \n",
    "> `source ~/.bash_profile`  \n",
    "\n",
    "- This will change the venv to base. Switch/Activate the environment  \n",
    "> `jenv doctor`  \n",
    "No JAVA_HOME set  \n",
    "- Add the installed java to jenv  \n",
    "> `jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home`  \n",
    "> `jenv add /Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home`  \n",
    "> `jenv versions`\n",
    "- Configure the java version which you want to use:  \n",
    "> `jenv global 11`  \n",
    "> `jenv versions`  \n",
    "- For v11\n",
    "> `echo 'export JAVA_HOME=$(/usr/libexec/java_home -v11)' >> ~/.bash_profile` \n",
    "- or for v1.8\n",
    "> `echo 'export JAVA_HOME=$(/usr/libexec/java_home -v1.8)' >> ~/.bash_profile` \n",
    "- If `jenv doctor` not set, use  \n",
    "> `echo 'eval \"$(jenv init -)\"' >> ~/.zshrc`   \n",
    "- Test `java --version` or `which java`\n",
    "- Setup PySpark\n",
    "> `RECO_ENV=$(conda env list | grep reco | awk '{print $NF}')`  \n",
    "> `mkdir -p $RECO_ENV/etc/conda/activate.d`  \n",
    "> `mkdir -p $RECO_ENV/etc/conda/deactivate.d`   \n",
    "- Then, create the file \\$RECO_ENV/etc/conda/activate.d/env_vars.sh and add:\n",
    "```\n",
    "#!/bin/sh\n",
    "RECO_ENV=$(conda env list | grep reco | awk '{print $NF}')\n",
    "export PYSPARK_PYTHON=$RECO_ENV/bin/python\n",
    "export PYSPARK_DRIVER_PYTHON=$RECO_ENV/bin/python\n",
    "unset SPARK_HOME\n",
    "```\n",
    "- This will export the variables every time we do `conda activate reco`. To unset these variables when we deactivate the environment, create the file $RECO_ENV/etc/conda/deactivate.d/env_vars.sh and add:\n",
    "```\n",
    "#!/bin/sh\n",
    "unset PYSPARK_PYTHON\n",
    "unset PYSPARK_DRIVER_PYTHON\n",
    "```\n",
    "- Register environment as kernel in Jupyter\n",
    "> `python -m ipykernel install --name reco --display-name \"Python (reco)\"`\n",
    "- Clone recommenders repo\n",
    "> `git clone https://github.com/microsoft/recommenders`\n",
    "- Change root directory of recommenders git folder where `setup.py` sits\n",
    "- Install recommenders and additional package setups\n",
    "> `pip install -e .`\n",
    "- To roll back to older java version\n",
    "> `jenv local 1.8`\n",
    "- Reinstate JAVA_HOME environment and relaunch kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS algorithm\n",
    "### Why not SVD\n",
    "### Sparsity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark internals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark MLlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements\n",
    "### Explicit rating\n",
    "### Implicit rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ec2189bea0434770dca7423a25e631e1cca9c4e2b4ff137a82f4dff32ac9607"
  },
  "kernelspec": {
   "display_name": "Python (reco)",
   "language": "python",
   "name": "reco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
