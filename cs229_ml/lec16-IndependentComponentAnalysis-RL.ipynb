{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7e6341",
   "metadata": {},
   "source": [
    ">>> Work in Progress (Following are the lecture notes of Prof Andrew Ng - CS229 - Stanford. This is my interpretation of his excellent teaching and I take full responsibility of any misinterpretation/misinformation provided herein.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea298f8",
   "metadata": {},
   "source": [
    "## Lecture 16\n",
    "\n",
    "#### Outline\n",
    "- Independent Component Analysis (ICA)\n",
    "  - CDFs (cumulative distribution function)\n",
    "  - ICA model\n",
    "- Reinforcement Learning \n",
    "  - MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715b1e8",
   "metadata": {},
   "source": [
    "### ICA problem statement\n",
    "- sound emitted by speaker j at time i = $s_{j}^{(i)}$\n",
    "- microphone record $x^{(i)} = As^{(i)}, x \\in \\mathbb R^{n}$\n",
    "  - say if you have n=2 speakers, A will be 2x2 matrix\n",
    "  - A is called mixing matrix\n",
    "  - assumption is number of speaker and microphone is same\n",
    "- __Goal__: Find $W = A^{-1}$, so $s^{(i)} = Wx^{(i)}$\n",
    "  - W is the unmixing matrix\n",
    "  - the speakers record different combination of speaker voices.\n",
    "  - Can we separate out the original n speaker speech signals?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62414190",
   "metadata": {},
   "source": [
    "- How is it possible to separate out?\n",
    "  - $s_{1}$ and $s_{2}$ are uniform between -1 and +1 (- Snapshot1 below)\n",
    "  - when this passes through mixing matrix A, the axis changes to $x_{1}$ and $x_{2}$ (- Snapshot2 below)\n",
    "  - on applying unmixing matrix W, the axis changes back to $s_{1}$ and $s_{2}$\n",
    "  - this transformation was possible because the source $s_{1}$ and $s_{2}$ were distributed uniformly between -1 and +1\n",
    "  - in realty in real time, human voices are not distributed uniformly between -1 and +1\n",
    "  - if the data is Gaussian, then ICA is not possible. Why?\n",
    "    - uniform distribution is highly non-Gaussian distribution, which makes ICA possible\n",
    "    - what if $s_{1}$ and $s_{2}$ came from Gaussian densities?\n",
    "      - if so, the distribution $s_{1}$ and $s_{2}$ would be rotationally symmetric (- Snapshot3 below)\n",
    "      - there will be rotational ambiguity, any axis could be $s_{1}$ and $s_{2}$ \n",
    "      - you cannot map parallelogram back to square\n",
    "      - Gaussian distribution is rotationally symmetric\n",
    "    - so there is some ambiguity in the output of ICA \n",
    "  - there are two types of ambiguity here\n",
    "    - we dont know which is speaker 1 and which is speaker 2\n",
    "    - we can flip this data horizontally or vertically or reflect this and we wont be able to differentiate which one is +$s_{1}$ and which is -$s_{1}$\n",
    "      \n",
    "      \n",
    "    \n",
    "  \n",
    "  \n",
    "- Snapshot 1\n",
    "<img src=\"images/16_ica1.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS229-Andrew Ng}}$   \n",
    "\n",
    "- Snapshot 2\n",
    "<img src=\"images/16_ica2.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS229-Andrew Ng}}$   \n",
    "\n",
    "- Snapshot 3\n",
    "<img src=\"images/16_ica3.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS229-Andrew Ng}}$   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81257a",
   "metadata": {},
   "source": [
    "- Gaussian density is the only distribution that is rotationally symmetric\n",
    "- if $s_{1}$ and $s_{2}$ are independent and rotationally symmetric, then the distribution has circular contours and it must be Gaussian density\n",
    "- __ICA is possible only if data is non-Gaussian, and only then it is possible to recover the independent sources__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00294f5",
   "metadata": {},
   "source": [
    "### CDF\n",
    "- Relation between pdf and cdf\n",
    "> $p_{s}(s) = F'(s)$\n",
    "\n",
    "<img src=\"images/16_cdf.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS229-Andrew Ng}}$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca0bd27",
   "metadata": {},
   "source": [
    "### ICA derivation\n",
    "- Let the cdf be $F(s)$ and its corresponding pdf be $p_{s}(s)$\n",
    "- Our model is $x = As = w^{-1}s$ and $s=wx$\n",
    "- If we know $p_{s}(s)$, what is the density of $p_{x}(x)$\n",
    "  - We might consider $p_{x}(x) = p_{s}(wx) = p_{s}(s)$, assuming w is an invertible matrix, this is a bijection. There is a one-to-one mapping between x and s.\n",
    "    - This is incorrect\n",
    "    - This works for probability mass function for discrete probability distribution but not for continuous probability distribution\n",
    "    - The correct answer is $p_{x}(x) = p_{s}(wx)|w| = p_{s}(s)|w|$, where $|w|$ is the determinant of matrix w\n",
    "    \n",
    "- We want to compute density of x because in the training set, we get to observe x only. To find the MLE parameters, we need to know the density of x, so that we can map and choose parameters W to maximize the likelihood. \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad8ff6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73bfca27",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5a323d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e81390d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78683d08",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3b14809",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ed47f8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32bc7bef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c02a302c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6494e77b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
