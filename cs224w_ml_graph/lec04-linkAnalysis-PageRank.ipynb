{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e02dbc2a",
   "metadata": {},
   "source": [
    ">>> Work in progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4675d3aa",
   "metadata": {},
   "source": [
    "### Graph as Matrix\n",
    "- determine the node importance using random walk - PageRank\n",
    "- obtain node embeddings in the form of matrix factorization\n",
    "- random walk, MF and node embeddings relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c1cf6",
   "metadata": {},
   "source": [
    "### PageRank\n",
    "- Web as a graph\n",
    "  - Node - web page\n",
    "  - Edge - hyperlink\n",
    "  - lot of static pages (navigational)\n",
    "  - now-a-days there are lot of transactional pages\n",
    "- represent as directed graph\n",
    "- what page on web is more important than other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ab1f1",
   "metadata": {},
   "source": [
    "#### Link Analysis\n",
    "- compute importanceo of nodes in graph\n",
    "  - PageRank\n",
    "  - Personalized Page rank\n",
    "  - Random walk with restarts\n",
    "- all in-links are equal?\n",
    "  - recursive question\n",
    "- the flow model\n",
    "  - in-links\n",
    "  - out-links\n",
    "  - are all in-links equal\n",
    "    - links from important pages count more\n",
    "\n",
    "##### The flow model\n",
    "- it works on the vote model\n",
    "- a vote from important page has higher importance\n",
    "- a page is important if it is pointed to by other important pages\n",
    "- if page $i$ with importance $r_{i}$ has $d_{i}$ out-links, each link gets $r_{i}/d_{i}$ votes\n",
    "  - For example, node k has 4 out links, so it shares it as $r_{k}/4$\n",
    "> rank $r_{j} = \\sum\\limits_{i \\rightarrow j} \\frac{r_{i}}{d_{i}}$  \n",
    "> $d_{i}$ - out-degree of node i\n",
    "\n",
    "<img src=\"./images/04_pageRank_FlowModel.png\" width=200 height=200>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56f82e",
   "metadata": {},
   "source": [
    "- solving this with Gaussian elimination is not a scalable problem\n",
    "\n",
    "<img src=\"./images/04_pageRank_FlowModel3.png\" width=200 height=200>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392d2077",
   "metadata": {},
   "source": [
    "##### Stochastic adjacency matrix\n",
    "- If j points to i ($j \\rightarrow i$), then $M_{ij} = \\frac{1}{d_{j}}$\n",
    "- M is a column stochastic matrix\n",
    "- cols sum to 1\n",
    "- prob distribution over matrix M\n",
    "- rank vector - $\\sum_{i}r_{i} = 1$\n",
    "- the flow equation can be written as \n",
    "> $r = M.r$  \n",
    "> or, $r_{j} = \\sum\\limits_{i \\rightarrow j} \\frac{r_{i}}{d_{\\text{out}-i}}$ \n",
    "\n",
    "<img src=\"./images/04_pageRank_Matrix.png\" width=200 height=200>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698880f6",
   "metadata": {},
   "source": [
    "#### Connection to Random walk\n",
    "- random web surfer\n",
    "- at time t, he is on page i\n",
    "- at time t+1, he follows an out-link from i _uniformly at random_\n",
    "- and ends up at page j\n",
    "- repeats the process indefinitely\n",
    "- p(t) vector in which the coordinate prob that he is at page i at time t\n",
    "- p(t) is the prob distribution over pages\n",
    "- where is the surfer at time t+1\n",
    "> p(t+1) = M.p(t)\n",
    "- p(t) is the prob vector where the random walker was at prev time step\n",
    "- p(t+1) is the prob distrib/vector of where the walker will be at the next time step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbae83c",
   "metadata": {},
   "source": [
    "#### The stationary distribution\n",
    "- suppose the random walk reaches a steady state at time t\n",
    "- p(t) is a stationary distribution of random walk\n",
    "> p(t+1) = M.p(t) = p(t)\n",
    "- so the original rank vector r is a stationary distribution for the random walk\n",
    "\n",
    "#### Eigenvector of matrix\n",
    "- Adjacency matrix satisfies $\\lambda c = A c$\n",
    "- c: eigenvector, $\\lambda$: eigenvalue\n",
    "\n",
    "#### Eigenvector formulation\n",
    "- Power iteration\n",
    "    - starting from any vector u, the limit M(M(M...(M(Mu))) is the long-term distribution of surfer\n",
    "    - r is the principal eigenvector of M with eigenvalue 1\n",
    "    - the flow equation 1.r = Mr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0e0ba",
   "metadata": {},
   "source": [
    "### How to solve PageRank\n",
    "- given a graph with n nodes, use iterative procedure\n",
    "  - randomly assign each node an initial page rank\n",
    "  - repeat until the vector r stabilizes/converge $\\sum_{i}|r_{i}^{t+1} - r_{i}^{t}| < \\epsilon$\n",
    "    - calculate page rank of each node\n",
    "    > $r_{j}^{(t+1)} = \\sum\\limits_{i \\rightarrow j} \\frac{r_{i}^{(t)}}{d_{\\text{out}-i}}$ \n",
    "- generally speaking, it takes 50 iterations to reach stationary distribution or limiting solution\n",
    "- Google runs this algorithm every day on the entire web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19be27b6",
   "metadata": {},
   "source": [
    "#### Dead-ends and Spider-traps\n",
    "- Adding random uniform teleportation solves issues of dead-ends(no out-links) and spider-traps(all out-links are within the group)\n",
    "- Spider traps\n",
    "  - with prob $\\beta$, follow a link at random\n",
    "  - with prob $1-\\beta$, jump to a random page\n",
    "  - $\\beta$ generally is in the range of 0.8 to 0.9\n",
    "- Dead-ends\n",
    "  - random teleport links with total prob of 1\n",
    "\n",
    "<img src=\"./images/04_pageRank_DeadEnd.png\" width=200 height=200>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6236db",
   "metadata": {},
   "source": [
    "#### PageRank equation\n",
    "> $r_{j} = \\sum\\limits_{i \\rightarrow j} \\beta\\frac{r_{i}}{d_{i}} + (1-\\beta)\\frac{1}{N}$ - flow based formulation   \n",
    "> $G = \\beta M + (1-\\beta)[\\frac{1}{N}]_{NxN}$ - matrix equation \n",
    "> $r = G.r$ - recursive problem  \n",
    "- this formulation assumes that M has no dead ends, either preprocess matrix M to remove all dead ends or explicitly follow random teleport links with prob 1.0 from dead ends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06371def",
   "metadata": {},
   "source": [
    "### Random walk with restarts and personalized PageRank\n",
    "- suppose there is a bipartite graph representing user and item interactions\n",
    "- for example recommendation from Amazon, based on the user purchase items\n",
    "- the next question that occurs is, based on the past order history, what item will he purchase next?\n",
    "- or based on items Q and P sell history from similar users, will user recommend item P when user interacts with Q\n",
    "- how to define the concept of proximity or relatedness of different items in this graph?\n",
    "- which is more related A,A' or B,B'\n",
    "\n",
    "<img src=\"./images/04_bipartiteUserItemGraph1.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0142df37",
   "metadata": {},
   "source": [
    "#### Node proximity measures\n",
    "- If we look at A,A', B,B' only\n",
    "  - A has a shorter path than B and B', so A and A' are more related\n",
    "- but if we look at C and C' which has 2 users, say both purchased these 2 items, then C and C' are more related as they have common neighbor\n",
    "- We need to design algorithm/metric that considers the shortest path but also considers the common neighbor and how many different paths allow you to go from one to another\n",
    "\n",
    "\n",
    "<img src=\"./images/04_bipartiteNodeProximity1.png\" width=400 height=400>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1fb68d",
   "metadata": {},
   "source": [
    "- PageRank can help to solve this\n",
    "- suppose another new user has purchased item D and D'\n",
    "- but has enjoyed buying lot of other items\n",
    "- so the relationship is less strong than users of item C and C'\n",
    "\n",
    "<img src=\"./images/04_bipartiteNodeProximity2.png\" width=400 height=200>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e967eb7",
   "metadata": {},
   "source": [
    "#### Proximity on graphs\n",
    "\n",
    "##### PageRank\n",
    "- how does the notion of PageRank gets extended here\n",
    "- PageRank tells me the importance of node on graph and ranks nodes by importance\n",
    "- it has a notion of teleport where a random surfer teleports uniformly over any node in graph\n",
    "- S = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "\n",
    "##### Personalized PageRank\n",
    "- in this extension of PageRank, when it teleports, it does not teleport to anywhere, instead it teleports to a subset of nodes S\n",
    "- S = [0.1, 0, 0, 0.2, 0, 0, 0.5, 0, 0, 0.2]\n",
    "\n",
    "##### Proximity on graphs\n",
    "- when it teleports, if it teleports to a single node S, which is the starting node\n",
    "- this is called _Random Walk with Restart_\n",
    "- S = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66f35ae",
   "metadata": {},
   "source": [
    "#### Random walk with Restart - Algorithm\n",
    "- Query Nodes Q\n",
    "- Proximity to query node\n",
    "- Number of visits by random walk starting at Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8902f225",
   "metadata": {},
   "source": [
    "### Matrix Factorization and Node Embeddings\n",
    "- two nodes are similar if they coappear in the same random walk, starting at a given node\n",
    "\n",
    "#### Node similarity\n",
    "- factorize adjacency matrix as a product of $Z$ and $Z^{T}$\n",
    "> $Z^{T}Z = A$\n",
    "\n",
    "#### Matrix Factorization\n",
    "- the embedding matrix dimension d (number of rows) is much smaller than number of nodes n\n",
    "- so exact factorization $A = Z^{T}Z$ is not possible\n",
    "- to learn Z approximately\n",
    "  - find the matrix Z such that\n",
    "  > min$_{Z}\\Vert A - Z^{T}Z\\Vert_{2}$\n",
    "  - use L2 norm or softmax function\n",
    "- The inner product decoder with node similarity defined by edge connectvity is equivalent to matrix factorization of adjacency matrix A\n",
    "- approximate A by the embeddings of the nodes such that if two nodes are linked then the dot product should be equal to 1 otherwise 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53e578",
   "metadata": {},
   "source": [
    "#### Random walk based similarity\n",
    "- Deepwalk and node2vec have more complex node similarity based on random walks\n",
    "- Deepwalk Equation  \n",
    "\n",
    "<img src=\"./images/04_matrixFac_DeepwalkEqn.png\" width=400 height=200>  \n",
    "$\\tiny{\\text{YouTube-Stanford-CS224W-Jure Leskovec}}$\n",
    "\n",
    "##### Limitations 1\n",
    "- if new nodes are appearing over time, then the nodes that are not in the embedding computations and will not be calculated\n",
    "\n",
    "##### Limitations 2\n",
    "- structural similarity - even if there are two different graphs, their local network structure is very similar \n",
    "  - node2vec and deepwalk will come up with very different embedding for these structural similar network\n",
    "  - it wont be able to compute structural similarity\n",
    "  - but it will be able to capture the identities of neighbors next to a given starting node\n",
    "  - anonymous walks will be able to capture the structural similarity\n",
    "\n",
    "##### Limitations 3\n",
    "- this approach cannot utilize node edge in graph level features, i.e., feature vector attached to nodes, edges and graphs do not work in this framework\n",
    "  - the solution is deep representation learning and graph neural network\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
